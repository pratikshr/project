library(MASS)
data(shuttle)
head(shuttle)
shuttle$auto <- 1 * (shuttle$use == "auto")
head(shuttle)
unique(shuttle$auto)
View(shuttle)
InsectSprays
fit <- glm(count ~ relevel(spray, "B"), data = InsectSprays, family = poisson)
relevel(spray, "B")
?relevel
exp(coef(fit))
?table
a <- letters[1:3]
table(a, sample(a))
a
table(a)
table(,a)
table(a,a)
sample(a)
library(kernlab)
data(spam)
set.seed(333)
dim(spam)[1]
sample(dim(spam)[1])
sample(dim(spam)[1], 10)
sample(spam, 10)
sample(spam[1], 10)
?sample
View(spam)
sample(dim(spam)[1], 10)
dim(spam)
dim(spam)[1]
sample(4601, 10)
sample(4601, 10)
?plot
smallSpam <- spam[sample(dim(spam)[1], size = 10), ]
View(smallSpam)
spamLabel <- (smallSpam$type == "spam")*1 + 1
plot(smallSpam$capitalAve)
plot(smallSpam$capitalAve, col = spamLabel)
plot(smallSpam$capitalAve, col = smallSpam$type)
plot(smallSpam$capitalAve, col = smallSpam$type)
x <- c(1,2,3,4,5,6,7,3,2,4)
length(x)
prediction <- rep(NA, 10)
class(prediction)
prediction[x>3]
x>3
install.packages("caret")
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
predictors
class(predictors)
dim(predictors)
dim(diagnosis)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
class(inTrain)
inTrain1 = createDataPartition(mixtures$CompressiveStrength, p = 3/4, list = FALSE)
class(inTrain1)
str(inTrain)
str(inTrain1)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
View(concrete)
xnames <- colnames(concrete)[1:8]
featurePlot(x=training[, xnames], y=training$CompressiveStrength, plot="pairs")
index <- seq_along(1:nrow(training))
ggplot(data=training, aes(x=index, y=CompressiveStrength)) + geom_point() +
theme_bw()
library(Hmisc)
cutCompressiveStrength <- cut2(training$CompressiveStrength, g=4)
summary(cutCompressiveStrength)
ggplot(data=training, aes(y=index, x=cutCompressiveStrength)) +
geom_boxplot() + geom_jitter(col="blue") + theme_bw()
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
intt <- createDataPartition(mixtures, p = .75, list = F)
intt <- createDataPartition(mixtures, p = .75, list = FALSE)
intt <- createDataPartition(mixtures, p = .75)
y
y
?createDataPartition
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
class(diagnosis)
str(diagnosis)
summary(diagnosis)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
ggplot(data=training, aes(x=Superplasticizer)) + geom_histogram() + theme_bw()
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
grep('^IL', x = names(training)
)
?grep
grep("[a-z]", letters)
names(training)
ss <- training[,grep('^IL', x = names(training) )]
View(ss)
preProc <- preProcess(ss, method='pca', thresh=0.9,
outcome=training$diagnosis)
preProc
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p=3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
IL <- grep("^IL", colnames(training), value=TRUE)
ILpredictors <- predictors[, IL]
df <- data.frame(diagnosis, ILpredictors)
predictors[, IL]
View(predictors)
ILpredictors
ILpredictors <- predictors[, IL]
df <- data.frame(diagnosis, ILpredictors)
inTrain <- createDataPartition(df$diagnosis, p=3/4)[[1]]
training <- df[inTrain, ]
testing <- df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method="glm", data=training)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p=3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
IL <- grep("^IL", colnames(training), value=TRUE)
ILpredictors <- predictors[, IL]
df <- data.frame(diagnosis, ILpredictors)
inTrain <- createDataPartition(df$diagnosis, p=3/4)[[1]]
training <- df[inTrain, ]
testing <- df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method="glm", data=training)
predictions <- predict(modelFit, newdata=testing)
install.packages("e1071")
modelFit <- train(diagnosis ~ ., method="glm", data=training)
predictions <- predict(modelFit, newdata=testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
acc1 <- C1$overall[1]
acc1 # Non-PCA Accuracy: 0.65
modelFit <- train(training$diagnosis ~ .,
method="glm",
preProcess="pca",
data=training,
trControl=trainControl(preProcOptions=list(thresh=0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
acc2 <- C2$overall[1]
acc2
data(iris)
library(ggplot2)
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y = iris$Species, p = 0.7, list = F)
library(caret)
inTrain <- createDataPartition(y = iris$Species, p = 0.7, list = F)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
ggplot(data = training, aes(x = Petral.Width, y = Sepal.Width, colour = Species)) + geom_point()
ggplot(data = training, aes(x = Petal.Width, y = Sepal.Width, colour = Species)) + geom_point()
modFit <- train(Species ~ ., method = "rpart", data = training)
modFit
modFit$FinalModel
modFit$finalModel
str(modFit)
modFit$finalModel
plot(modFit$finalModel)
plot(modFit$finalModel, uniform = T, main = "Classification Tree")
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = T)
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = T, all = T, cex = .8)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
?fancyRpartPlot
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(modFit$finalModel)
predict(modFit, testing)
install.packages("ElemStatLearn")
library("ElemStatLearn", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
data(ozone, package = "ElemStatLearn")
ozone <- ozone[order(ozone$ozone),]
head(ozone)
ll <- matrix(NA, nrow = 10, ncol = 155)
for(i in 1:10){}
for(i in 1:10){
ss <- sample(1:dim(ozone), replace = T)
ozone0 <- ozone[ss,]
ozone0 <- ozone0[order(ozone0$ozone)]
loess0 <- loess(temperature ~ ozone, ozone0, span = .2)
ll[i,] <- predict(loess0, newdata = data.frame(ozone = 1:155))
]
sample(1:dim(ozone)[1]
sample(1:dim(ozone)[1], replace = T)
order(ozone0$ozone)
order(ozone$ozone)
ss <- sample(1:dim(ozone), replace = T)
ss <- sample(1:dim(ozone)[1], replace = T)
ozone0 <- ozone[ss,]
View(ozone)
View(ozone0)
ozone0 <- ozone0[order(ozone0$ozone),]
View(ozone0)
ozone0 <- ozone[ss,]
View(ozone0)
View(ozone)
head(ozone)
ss <- sample(1:dim(ozone)[1], replace = T)
ss
ozone0 <- ozone[ss,]
ozone0
ozone[95,]
ozone[36,]
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
training = segmentationOriginal[segmentationOriginal$Case == "Train",]
testing = segmentationOriginal[segmentationOriginal$Case == "Test",]
set.seed(125)
M <- train(Class ~ ., data=training, method="rpart")
M
M$finalModel
plot(M$finalModel)
text(M$finalModel)
predict(M, newdata = data.frame(TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2 ))
data.frame(TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2 )
data.frame(TotalIntench2 = 23,000, FiberWidthCh1 = 10, PerimStatusCh1=2 )
xxx <- data.frame(TotalIntench2 = 23,000, FiberWidthCh1 = 10, PerimStatusCh1=2 )
predict(M, newdata = xxx)
install.packages("pgmm")
library("pgmm", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
library(pgmm)
data(olive)
dim(olive)
head(olive)
olive <- olive[,-1]
head(olive)
treeModel <- train(Area ~ ., data=olive, method="rpart2")
treeModel
newdata <- as.data.frame(t(colMeans(olive)))
predict(treeModel, newdata)
unique(olive$Area)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train <- sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA <- SAheart[train,]
testSA <- SAheart[-train,]
set.seed(13234)
logitModel <- train(chd ~ age + alcohol + obesity + tobacco +
typea + ldl, data=trainSA, method="glm",
family="binomial")
logitModel
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
predictTrain <- predict(logitModel, trainSA)
predictTest <- predict(logitModel, testSA)
# Training Set Misclassification rate
missClass(trainSA$chd, predictTrain) # 0.2727273
# Test Set Misclassification rate
missClass(testSA$chd, predictTest)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.train)
head(vowel.test)
dim(vowel.train) # 528  11
dim(vowel.test) # 462  11
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
?randomForesty
?randomForest
install.packages("randomForest")
library("randomForest", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
varImp(modelRf)
install.packages("corrplot")
?complete.cases
?colSums
x <- cbind(x1 = 3, x2 = c(4:1, 2:5))
rowSums(x); colSums(x)
x
rowSums(x)
colSums(x)
colSums(is.na(x))
colSums(!is.na(x))
!is.na(x)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
setwd("~/Documents/GITHUB/Data Science/practical machine learning/project")
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
source.with.encoding('~/.active-rstudio-document', encoding='UTF-8', echo=TRUE)
sum(complete.cases(trainRaw))
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
getwd()
trainRaw <- read.csv("./data/pml-training.csv")
testRaw <- read.csv("./data/pml-testing.csv")
dim(trainRaw)
dim(testRaw)
sum(complete.cases(trainRaw))
trainRaw <- trainRaw[, colSums(is.na(trainRaw)) == 0]
testRaw <- testRaw[, colSums(is.na(testRaw)) == 0]
classe <- trainRaw$classe
trainRemove <- grepl("^X|timestamp|window", names(trainRaw))
?grepl
names(trainRaw)
trainRemove
grepl("[timestamp]", names(trainRaw))
grepl("timestamp", names(trainRaw))
grepl("^timestamp", names(trainRaw))
grepl("timestamp", names(trainRaw))
grepl("[timestamp]", names(trainRaw))
grepl("timestamp", names(trainRaw))
grepl("^timestamp", names(trainRaw))
grepl("^X", names(trainRaw))
trainRaw <- trainRaw[, colSums(is.na(trainRaw)) == 0]
testRaw <- testRaw[, colSums(is.na(testRaw)) == 0]
trainRemove <- grepl("^X|timestamp|window", names(trainRaw))
trainRaw <- trainRaw[, !trainRemove]
sapply(trainRaw, is.numeric)
trainCleaned <- trainRaw[, sapply(trainRaw, is.numeric)]
trainCleaned$classe <- classe
testRemove <- grepl("^X|timestamp|window", names(testRaw))
testRaw <- testRaw[, !testRemove]
testCleaned <- testRaw[, sapply(testRaw, is.numeric)]
complete.cases(trainCleaned)
sum(complete.cases(trainCleaned))
classe
set.seed(22519) # For reproducibile purpose
inTrain <- createDataPartition(trainCleaned$classe, p=0.70, list=F)
trainData <- trainCleaned[inTrain, ]
testData <- trainCleaned[-inTrain, ]
controlRf <- trainControl(method="cv", 5)
?postResample
result <- predict(modelRf, testCleaned[, -length(names(testCleaned))])
controlRf <- trainControl(method="cv", 5)
modelRf <- train(classe ~ ., data=trainData, method="rf", trControl=controlRf, ntree=250)
modelRf
View(trainCleaned)
View(testCleaned)
answers <- result
modelRf
predictRf <- predict(modelRf, testData)
confusionMatrix(testData$classe, predictRf)
accuracy <- postResample(predictRf, testData$classe)
accuracy
oose <- 1 - as.numeric(confusionMatrix(testData$classe, predictRf)$overall[1])
oose
result <- predict(modelRf, testCleaned[, -length(names(testCleaned))])
result
answers <- result
pml_write_files <- function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_results/problem_id_",i,".txt")
write.table(x[i], file=filename, quote=FALSE,
row.names=FALSE, col.names=FALSE)
}
}
pml_write_files(answers)
pml_write_files(answers)
